max_len: 1429
========== fold: 0 training ==========
DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-base",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 768,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.21.2",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

Epoch 1 - avg_train_loss: 0.2435  avg_val_loss: 0.1077  time: 737s
Epoch 1 - Score: 0.4648  Scores: [0.5066601220604168, 0.4530318931362232, 0.42444450254566457, 0.46690471160138985, 0.47430014693632594, 0.4634925230862983]
Epoch 1 - Save Best Score: 0.4648 Model
Epoch 2 - avg_train_loss: 0.1044  avg_val_loss: 0.1055  time: 730s
Epoch 2 - Score: 0.4596  Scores: [0.5033486025527704, 0.44940742601467215, 0.4146626044876014, 0.4570520259162597, 0.4756759772797414, 0.4573567968741074]
Epoch 2 - Save Best Score: 0.4596 Model
Epoch 3 - avg_train_loss: 0.0984  avg_val_loss: 0.1034  time: 733s
Epoch 3 - Score: 0.4550  Scores: [0.49888139390858305, 0.44832529917386954, 0.4119955269596158, 0.45557199287312533, 0.4706205853747145, 0.44458518868293956]
Epoch 3 - Save Best Score: 0.4550 Model
Epoch 4 - avg_train_loss: 0.0947  avg_val_loss: 0.1026  time: 730s
Epoch 4 - Score: 0.4532  Scores: [0.49628091674571173, 0.4455979170690952, 0.4106427352929745, 0.45434204452482485, 0.4690285516860569, 0.44341884942820387]
Epoch 4 - Save Best Score: 0.4532 Model
========== fold: 0 result ==========
Score: 0.4532  Scores: [0.49628091674571173, 0.4455979170690952, 0.4106427352929745, 0.45434204452482485, 0.4690285516860569, 0.44341884942820387]
========== fold: 1 training ==========
DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-base",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 768,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.21.2",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

Epoch 1 - avg_train_loss: 0.2638  avg_val_loss: 0.1274  time: 731s
Epoch 1 - Score: 0.5063  Scores: [0.5542271655030179, 0.4932874532437889, 0.4359153486962783, 0.5271044686738747, 0.519118935111713, 0.5083861355042396]
Epoch 1 - Save Best Score: 0.5063 Model
Epoch 2 - avg_train_loss: 0.1024  avg_val_loss: 0.1093  time: 729s
Epoch 2 - Score: 0.4686  Scores: [0.504069045542625, 0.4599679572058481, 0.4269646831025853, 0.46198058755908106, 0.487962705302739, 0.47035627033440486]
Epoch 2 - Save Best Score: 0.4686 Model
Epoch 3 - avg_train_loss: 0.0985  avg_val_loss: 0.1096  time: 731s
Epoch 3 - Score: 0.4693  Scores: [0.49909885673839316, 0.4583623128770631, 0.43013953203348376, 0.4693714906499905, 0.4909789295038222, 0.46810942041598086]
Epoch 4 - avg_train_loss: 0.0949  avg_val_loss: 0.1072  time: 730s
Epoch 4 - Score: 0.4639  Scores: [0.4939749275357423, 0.45329607463310456, 0.4254544273069848, 0.4596090778254902, 0.48526800604761644, 0.4658903373776865]
Epoch 4 - Save Best Score: 0.4639 Model
========== fold: 1 result ==========
Score: 0.4639  Scores: [0.4939749275357423, 0.45329607463310456, 0.4254544273069848, 0.4596090778254902, 0.48526800604761644, 0.4658903373776865]
========== fold: 2 training ==========
DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-base",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 768,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.21.2",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

Epoch 1 - avg_train_loss: 0.2809  avg_val_loss: 0.1271  time: 747s
Epoch 1 - Score: 0.5067  Scores: [0.5016851810756293, 0.5255863274870054, 0.4921954989928928, 0.5145841144713795, 0.5141297270134335, 0.4921568794851461]
Epoch 1 - Save Best Score: 0.5067 Model
Epoch 2 - avg_train_loss: 0.1086  avg_val_loss: 0.1124  time: 752s
Epoch 2 - Score: 0.4752  Scores: [0.5093519535804351, 0.467605735794497, 0.4299838117752688, 0.4789026101114712, 0.4971552680841942, 0.4679886057554017]
Epoch 2 - Save Best Score: 0.4752 Model
Epoch 3 - avg_train_loss: 0.1004  avg_val_loss: 0.1089  time: 752s
Epoch 3 - Score: 0.4678  Scores: [0.49385842762762105, 0.45728693239543866, 0.4256669077577972, 0.47329496147423616, 0.49107309494383033, 0.4656162373573686]
Epoch 3 - Save Best Score: 0.4678 Model
Epoch 4 - avg_train_loss: 0.0962  avg_val_loss: 0.1083  time: 749s
Epoch 4 - Score: 0.4665  Scores: [0.48964283763690636, 0.4577284255738452, 0.4245966932393295, 0.47303808961594546, 0.4891359436887442, 0.4647717922948856]
Epoch 4 - Save Best Score: 0.4665 Model
========== fold: 2 result ==========
Score: 0.4665  Scores: [0.48964283763690636, 0.4577284255738452, 0.4245966932393295, 0.47303808961594546, 0.4891359436887442, 0.4647717922948856]
========== fold: 3 training ==========
DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-base",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 768,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.21.2",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

Epoch 1 - avg_train_loss: 0.2532  avg_val_loss: 0.1112  time: 751s
Epoch 1 - Score: 0.4731  Scores: [0.5005012418537296, 0.46543257913206254, 0.44547660383275745, 0.46720333111928686, 0.5012160158764442, 0.45897435250130747]
Epoch 1 - Save Best Score: 0.4731 Model
Epoch 2 - avg_train_loss: 0.1080  avg_val_loss: 0.1038  time: 747s
Epoch 2 - Score: 0.4566  Scores: [0.49212919015652346, 0.4485094813195356, 0.41845975705852156, 0.4458478018120468, 0.48825092716843815, 0.4463336106345232]
Epoch 2 - Save Best Score: 0.4566 Model
Epoch 3 - avg_train_loss: 0.1000  avg_val_loss: 0.1028  time: 751s
Epoch 3 - Score: 0.4542  Scores: [0.4891723046532314, 0.4455320455026745, 0.41829465539485156, 0.4443850836337923, 0.48392904196346687, 0.4438037911787747]
Epoch 3 - Save Best Score: 0.4542 Model
Epoch 4 - avg_train_loss: 0.0963  avg_val_loss: 0.1017  time: 742s
Epoch 4 - Score: 0.4518  Scores: [0.4887431541322364, 0.4444433643494257, 0.4151156035693289, 0.4410802954837393, 0.47884099673719016, 0.4425192999198614]
Epoch 4 - Save Best Score: 0.4518 Model
========== fold: 3 result ==========
Score: 0.4518  Scores: [0.4887431541322364, 0.4444433643494257, 0.4151156035693289, 0.4410802954837393, 0.47884099673719016, 0.4425192999198614]
========== CV ==========
Score: 0.4589  Scores: [0.4921697207975886, 0.45029914549646954, 0.4189978123596283, 0.4571601917184343, 0.48062743066096203, 0.45428496370782145]
