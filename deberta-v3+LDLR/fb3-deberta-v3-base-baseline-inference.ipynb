{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About this notebook\n- Deberta-v3-base starter code\n- pip wheels is [here](https://www.kaggle.com/code/yasufuminakama/fb3-pip-wheels)\n- Training notebook is [here](https://www.kaggle.com/code/yasufuminakama/fb3-deberta-v3-base-baseline-train)\n\nIf this notebook is helpful, feel free to upvote :)","metadata":{"papermill":{"duration":0.02594,"end_time":"2022-02-08T11:42:51.890919","exception":false,"start_time":"2022-02-08T11:42:51.864979","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# CFG","metadata":{"papermill":{"duration":0.026525,"end_time":"2022-02-08T11:42:51.944085","exception":false,"start_time":"2022-02-08T11:42:51.91756","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/fb3-deberta-v3-base-reinit-lastlayer-train/\"\n    config_path=path+'config.pth'\n    model=\"microsoft/deberta-v3-base\"\n    gradient_checkpointing=False\n    batch_size=24\n    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n    seed=42\n    n_fold=4\n    trn_fold=[0, 1, 2, 3]","metadata":{"papermill":{"duration":0.031276,"end_time":"2022-02-08T11:42:51.991958","exception":false,"start_time":"2022-02-08T11:42:51.960682","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Library","metadata":{"papermill":{"duration":0.015324,"end_time":"2022-02-08T11:42:52.022769","exception":false,"start_time":"2022-02-08T11:42:52.007445","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Library\n# ====================================================\nimport os\nimport gc\nimport re\nimport ast\nimport sys\nimport copy\nimport json\nimport time\nimport math\nimport string\nimport pickle\nimport random\nimport joblib\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\n\nos.system('pip uninstall -y transformers')\nos.system('pip uninstall -y tokenizers')\nos.system('python -m pip install --no-index --find-links=../input/fb3-pip-wheels transformers')\nos.system('python -m pip install --no-index --find-links=../input/fb3-pip-wheels tokenizers')\nimport tokenizers\nimport transformers\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\nfrom transformers import DataCollatorWithPadding\n%env TOKENIZERS_PARALLELISM=false\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"papermill":{"duration":19.692613,"end_time":"2022-02-08T11:43:11.730777","exception":false,"start_time":"2022-02-08T11:42:52.038164","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# tokenizer","metadata":{"papermill":{"duration":0.017982,"end_time":"2022-02-08T11:43:11.767286","exception":false,"start_time":"2022-02-08T11:43:11.749304","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')","metadata":{"papermill":{"duration":0.17588,"end_time":"2022-02-08T11:43:11.961555","exception":false,"start_time":"2022-02-08T11:43:11.785675","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{"papermill":{"duration":0.017596,"end_time":"2022-02-08T11:43:12.141759","exception":false,"start_time":"2022-02-08T11:43:12.124163","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Utils\n# ====================================================\ndef MCRMSE(y_trues, y_preds):\n    scores = []\n    idxes = y_trues.shape[1]\n    for i in range(idxes):\n        y_true = y_trues[:,i]\n        y_pred = y_preds[:,i]\n        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n        scores.append(score)\n    mcrmse_score = np.mean(scores)\n    return mcrmse_score, scores\n\n\ndef get_score(y_trues, y_preds):\n    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n    return mcrmse_score, scores\n\n\ndef get_logger(filename='inference'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()\n\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","metadata":{"papermill":{"duration":0.030498,"end_time":"2022-02-08T11:43:12.189984","exception":false,"start_time":"2022-02-08T11:43:12.159486","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# OOF","metadata":{"papermill":{"duration":0.01765,"end_time":"2022-02-08T11:43:12.225407","exception":false,"start_time":"2022-02-08T11:43:12.207757","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# oof\n# ====================================================\noof_df = pd.read_pickle(CFG.path+'oof_df.pkl')\nlabels = oof_df[CFG.target_cols].values\npreds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\nscore, scores = get_score(labels, preds)\nLOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')","metadata":{"papermill":{"duration":42.093803,"end_time":"2022-02-08T11:43:54.337033","exception":false,"start_time":"2022-02-08T11:43:12.24323","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading","metadata":{"papermill":{"duration":0.021365,"end_time":"2022-02-08T11:43:54.379768","exception":false,"start_time":"2022-02-08T11:43:54.358403","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Data Loading\n# ====================================================\ntest = pd.read_csv('../input/feedback-prize-english-language-learning/test.csv')\nsubmission = pd.read_csv('../input/feedback-prize-english-language-learning/sample_submission.csv')\n\nprint(f\"test.shape: {test.shape}\")\ndisplay(test.head())\nprint(f\"submission.shape: {submission.shape}\")\ndisplay(submission.head())","metadata":{"papermill":{"duration":0.976773,"end_time":"2022-02-08T11:43:55.377719","exception":false,"start_time":"2022-02-08T11:43:54.400946","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sort by length to speed up inference\ntest['tokenize_length'] = [len(CFG.tokenizer(text)['input_ids']) for text in test['full_text'].values]\ntest = test.sort_values('tokenize_length', ascending=True).reset_index(drop=True)\ndisplay(test.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"papermill":{"duration":0.023373,"end_time":"2022-02-08T11:43:55.501283","exception":false,"start_time":"2022-02-08T11:43:55.47791","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Dataset\n# ====================================================\ndef prepare_input(cfg, text):\n    inputs = cfg.tokenizer.encode_plus(\n        text, \n        return_tensors=None, \n        add_special_tokens=True, \n        #max_length=CFG.max_len,\n        #pad_to_max_length=True,\n        #truncation=True\n    )\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['full_text'].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, self.texts[item])\n        return inputs","metadata":{"papermill":{"duration":0.034236,"end_time":"2022-02-08T11:43:55.55924","exception":false,"start_time":"2022-02-08T11:43:55.525004","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"papermill":{"duration":0.023204,"end_time":"2022-02-08T11:43:55.605919","exception":false,"start_time":"2022-02-08T11:43:55.582715","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Model\n# ====================================================\nclass MeanPooling(nn.Module):\n    def __init__(self):\n        super(MeanPooling, self).__init__()\n        \n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        return mean_embeddings\n    \n\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n            self.config.hidden_dropout = 0.\n            self.config.hidden_dropout_prob = 0.\n            self.config.attention_dropout = 0.\n            self.config.attention_probs_dropout_prob = 0.\n            LOGGER.info(self.config)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n        if self.cfg.gradient_checkpointing:\n            self.model.gradient_checkpointing_enable()\n        self.pool = MeanPooling()\n        self.fc = nn.Linear(self.config.hidden_size, 6)\n        self._init_weights(self.fc)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n        return feature\n\n    def forward(self, inputs):\n        feature = self.feature(inputs)\n        output = self.fc(feature)\n        return output","metadata":{"papermill":{"duration":0.036876,"end_time":"2022-02-08T11:43:55.666198","exception":false,"start_time":"2022-02-08T11:43:55.629322","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# inference","metadata":{"papermill":{"duration":0.023567,"end_time":"2022-02-08T11:43:55.713142","exception":false,"start_time":"2022-02-08T11:43:55.689575","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# inference\n# ====================================================\ndef inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for inputs in tk0:\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        with torch.no_grad():\n            y_preds = model(inputs)\n        preds.append(y_preds.to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions","metadata":{"papermill":{"duration":0.03136,"end_time":"2022-02-08T11:43:55.768189","exception":false,"start_time":"2022-02-08T11:43:55.736829","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         collate_fn=DataCollatorWithPadding(tokenizer=CFG.tokenizer, padding='longest'),\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\npredictions = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions = np.mean(predictions, axis=0)","metadata":{"_kg_hide-output":true,"papermill":{"duration":78.050495,"end_time":"2022-02-08T11:45:13.842076","exception":false,"start_time":"2022-02-08T11:43:55.791581","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{"papermill":{"duration":0.027753,"end_time":"2022-02-08T11:45:13.90824","exception":false,"start_time":"2022-02-08T11:45:13.880487","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test[CFG.target_cols] = predictions\nsubmission = submission.drop(columns=CFG.target_cols).merge(test[['text_id'] + CFG.target_cols], on='text_id', how='left')\ndisplay(submission.head())\nsubmission[['text_id'] + CFG.target_cols].to_csv('submission.csv', index=False)","metadata":{"papermill":{"duration":0.043913,"end_time":"2022-02-08T11:45:13.979564","exception":false,"start_time":"2022-02-08T11:45:13.935651","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}