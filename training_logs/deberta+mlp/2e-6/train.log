max_len: 1429
========== fold: 0 training ==========
DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-base",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 768,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.21.2",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

Epoch 1 - avg_train_loss: 0.5365  avg_val_loss: 0.1198  time: 741s
Epoch 1 - Score: 0.4913  Scores: [0.5160428758391893, 0.46966657211152635, 0.4587258119168911, 0.49497493867963627, 0.5203757940370904, 0.4882185053151892]
Epoch 1 - Save Best Score: 0.4913 Model
Epoch 2 - avg_train_loss: 0.1177  avg_val_loss: 0.1127  time: 734s
Epoch 2 - Score: 0.4759  Scores: [0.5056748216048906, 0.4601916277589313, 0.4427872553499749, 0.4767721411486046, 0.50502274412977, 0.4651536768938691]
Epoch 2 - Save Best Score: 0.4759 Model
Epoch 3 - avg_train_loss: 0.1125  avg_val_loss: 0.1106  time: 738s
Epoch 3 - Score: 0.4714  Scores: [0.5062279341030695, 0.45772241198338937, 0.4378294346633954, 0.47306250455097076, 0.49188698795296565, 0.46149583359719365]
Epoch 3 - Save Best Score: 0.4714 Model
Epoch 4 - avg_train_loss: 0.1103  avg_val_loss: 0.1100  time: 734s
Epoch 4 - Score: 0.4698  Scores: [0.5037966407704993, 0.4566682599455463, 0.4361674326535523, 0.4712786010423545, 0.4923128459439782, 0.4585839033149411]
Epoch 4 - Save Best Score: 0.4698 Model
========== fold: 0 result ==========
Score: 0.4698  Scores: [0.5037966407704993, 0.4566682599455463, 0.4361674326535523, 0.4712786010423545, 0.4923128459439782, 0.4585839033149411]
========== fold: 1 training ==========
DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-base",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 768,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.21.2",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

Epoch 1 - avg_train_loss: 0.6302  avg_val_loss: 0.1238  time: 734s
Epoch 1 - Score: 0.4998  Scores: [0.5265858560831784, 0.4874423431830648, 0.45957221621549954, 0.4929690178196832, 0.5328610088202572, 0.49942339740200015]
Epoch 1 - Save Best Score: 0.4998 Model
Epoch 2 - avg_train_loss: 0.1145  avg_val_loss: 0.1167  time: 731s
Epoch 2 - Score: 0.4846  Scores: [0.5158513981520022, 0.4741416650384128, 0.44580504272583854, 0.4746377023174107, 0.5110696988103004, 0.4859629080309698]
Epoch 2 - Save Best Score: 0.4846 Model
Epoch 3 - avg_train_loss: 0.1097  avg_val_loss: 0.1153  time: 733s
Epoch 3 - Score: 0.4815  Scores: [0.513352403875166, 0.4693122269251891, 0.44472581829722413, 0.4731792991433848, 0.5074360794667362, 0.4809848674555522]
Epoch 3 - Save Best Score: 0.4815 Model
Epoch 4 - avg_train_loss: 0.1075  avg_val_loss: 0.1142  time: 732s
Epoch 4 - Score: 0.4791  Scores: [0.509075675960559, 0.46743497779847737, 0.44048092785044407, 0.4709832805006723, 0.5062707956671719, 0.4804685675466562]
Epoch 4 - Save Best Score: 0.4791 Model
========== fold: 1 result ==========
Score: 0.4791  Scores: [0.509075675960559, 0.46743497779847737, 0.44048092785044407, 0.4709832805006723, 0.5062707956671719, 0.4804685675466562]
========== fold: 2 training ==========
DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-base",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 768,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.21.2",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

Epoch 1 - avg_train_loss: 0.6915  avg_val_loss: 0.1383  time: 751s
Epoch 1 - Score: 0.5296  Scores: [0.5713208209726497, 0.5127378685112699, 0.467572509374277, 0.5331909092089339, 0.5519218433973553, 0.540828179739606]
Epoch 1 - Save Best Score: 0.5296 Model
Epoch 2 - avg_train_loss: 0.1202  avg_val_loss: 0.1209  time: 756s
Epoch 2 - Score: 0.4936  Scores: [0.5199350303025345, 0.4837847346004962, 0.4465011457885917, 0.49659039126924687, 0.524593779529064, 0.4903858096552251]
Epoch 2 - Save Best Score: 0.4936 Model
Epoch 3 - avg_train_loss: 0.1142  avg_val_loss: 0.1172  time: 756s
Epoch 3 - Score: 0.4855  Scores: [0.519652281630926, 0.4701794792918083, 0.4399527089679855, 0.4830146320753997, 0.5118062722709903, 0.4882286255579081]
Epoch 3 - Save Best Score: 0.4855 Model
Epoch 4 - avg_train_loss: 0.1113  avg_val_loss: 0.1162  time: 753s
Epoch 4 - Score: 0.4836  Scores: [0.5110269002762201, 0.469430231168048, 0.4406354461229707, 0.4829816173985039, 0.5106105954863105, 0.4871739566450226]
Epoch 4 - Save Best Score: 0.4836 Model
========== fold: 2 result ==========
Score: 0.4836  Scores: [0.5110269002762201, 0.469430231168048, 0.4406354461229707, 0.4829816173985039, 0.5106105954863105, 0.4871739566450226]
========== fold: 3 training ==========
DebertaV2Config {
  "_name_or_path": "microsoft/deberta-v3-base",
  "attention_dropout": 0.0,
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-07,
  "max_position_embeddings": 512,
  "max_relative_positions": -1,
  "model_type": "deberta-v2",
  "norm_rel_ebd": "layer_norm",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "pooler_dropout": 0,
  "pooler_hidden_act": "gelu",
  "pooler_hidden_size": 768,
  "pos_att_type": [
    "p2c",
    "c2p"
  ],
  "position_biased_input": false,
  "position_buckets": 256,
  "relative_attention": true,
  "share_att_key": true,
  "transformers_version": "4.21.2",
  "type_vocab_size": 0,
  "vocab_size": 128100
}

Epoch 1 - avg_train_loss: 0.5819  avg_val_loss: 0.1194  time: 753s
Epoch 1 - Score: 0.4910  Scores: [0.5191993221997714, 0.47231217360849787, 0.4651598097126536, 0.46782415478315637, 0.5258894283625659, 0.49589749370667024]
Epoch 1 - Save Best Score: 0.4910 Model
Epoch 2 - avg_train_loss: 0.1167  avg_val_loss: 0.1138  time: 750s
Epoch 2 - Score: 0.4790  Scores: [0.5148316604229566, 0.46851708328246355, 0.443210152580716, 0.46311826062791156, 0.510297934114837, 0.47427082583898833]
Epoch 2 - Save Best Score: 0.4790 Model
Epoch 3 - avg_train_loss: 0.1126  avg_val_loss: 0.1124  time: 754s
Epoch 3 - Score: 0.4758  Scores: [0.5069939670130691, 0.4639398856544539, 0.4366745940348175, 0.46177905113192413, 0.5108536707038592, 0.4743143260093919]
Epoch 3 - Save Best Score: 0.4758 Model
Epoch 4 - avg_train_loss: 0.1096  avg_val_loss: 0.1103  time: 744s
Epoch 4 - Score: 0.4713  Scores: [0.5033316747245699, 0.46088991035205407, 0.4346185744772727, 0.4584999701648458, 0.5026815720471564, 0.46754424998073413]
Epoch 4 - Save Best Score: 0.4713 Model
========== fold: 3 result ==========
Score: 0.4713  Scores: [0.5033316747245699, 0.46088991035205407, 0.4346185744772727, 0.4584999701648458, 0.5026815720471564, 0.46754424998073413]
========== CV ==========
Score: 0.4760  Scores: [0.5068180199938503, 0.4636329339892587, 0.4379829149039594, 0.4710154633066133, 0.5030135779766984, 0.4735711673244099]
